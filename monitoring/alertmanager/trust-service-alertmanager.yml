# Alertmanager configuration for Trust Service
# Comprehensive alert routing, grouping, and notification management

global:
  # SMTP configuration for email notifications
  smtp_smarthost: "${SMTP_HOST:-localhost:587}"
  smtp_from: "${SMTP_FROM:-alerts@marty.com}"
  smtp_auth_username: "${SMTP_USERNAME:-}"
  smtp_auth_password: "${SMTP_PASSWORD:-}"
  smtp_require_tls: true
  
  # Slack webhook configuration
  slack_api_url: "${SLACK_API_URL:-}"
  
  # PagerDuty integration key
  pagerduty_url: "https://events.pagerduty.com/v2/enqueue"
  
  # Default values for all alerts
  resolve_timeout: 5m

# Define routes for different alert types and severities
route:
  group_by: ['alertname', 'service', 'severity']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 12h
  receiver: 'default-notifications'
  
  routes:
    # Critical security alerts - immediate escalation
    - match:
        severity: critical
        alert_type: security
      receiver: 'security-critical'
      group_wait: 10s
      group_interval: 1m
      repeat_interval: 5m
      continue: true
    
    # Critical system alerts - immediate escalation
    - match:
        severity: critical
      receiver: 'platform-critical'
      group_wait: 10s
      group_interval: 1m
      repeat_interval: 30m
      continue: true
    
    # SLA violations - business team notification
    - match:
        alert_type: sla
      receiver: 'business-team'
      group_wait: 2m
      group_interval: 10m
      repeat_interval: 1h
    
    # Security warnings
    - match:
        team: security
        severity: warning
      receiver: 'security-warnings'
      group_wait: 1m
      group_interval: 5m
      repeat_interval: 2h
    
    # Platform warnings
    - match:
        team: platform
        severity: warning
      receiver: 'platform-warnings'
      group_wait: 2m
      group_interval: 10m
      repeat_interval: 4h
    
    # Business alerts
    - match:
        team: business
      receiver: 'business-team'
      group_wait: 5m
      group_interval: 15m
      repeat_interval: 6h
    
    # Compliance alerts
    - match:
        team: compliance
      receiver: 'compliance-team'
      group_wait: 1m
      group_interval: 5m
      repeat_interval: 1h
    
    # Escalation alerts
    - match:
        escalation: "true"
      receiver: 'escalation-team'
      group_wait: 0s
      group_interval: 1m
      repeat_interval: 10m

# Alert suppression rules
inhibit_rules:
  # Suppress warning alerts when critical alerts are firing
  - source_match:
      severity: critical
    target_match:
      severity: warning
    equal: ['service', 'alertname']
  
  # Suppress individual service alerts when multiple failures detected
  - source_match:
      alertname: MultipleSystemFailures
    target_match_re:
      alertname: ^(TrustService|Database|GRPC).*
    equal: ['service']
  
  # Suppress performance alerts when service is down
  - source_match:
      alertname: TrustServiceDown
    target_match_re:
      alertname: ^(TrustServiceHigh|GRPCHigh|DatabaseQuery).*
    equal: ['service']

# Notification receivers configuration
receivers:
  # Default notifications - low priority alerts
  - name: 'default-notifications'
    email_configs:
      - to: '${DEFAULT_EMAIL:-platform-alerts@marty.com}'
        subject: '[ALERT] {{ .GroupLabels.alertname }} - {{ .GroupLabels.service }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          Severity: {{ .Labels.severity }}
          Runbook: {{ .Annotations.runbook_url }}
          Dashboard: {{ .Annotations.dashboard_url }}
          {{ end }}
        headers:
          X-Alert-Priority: 'low'
    
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_DEFAULT:-}'
        channel: '#trust-service-alerts'
        title: 'Trust Service Alert'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}
          Service: {{ .Labels.service }} | Severity: {{ .Labels.severity }}
          {{ end }}
        color: 'warning'

  # Critical security alerts
  - name: 'security-critical'
    pagerduty_configs:
      - routing_key: '${PAGERDUTY_SECURITY_KEY:-}'
        description: 'CRITICAL SECURITY: {{ .GroupLabels.alertname }}'
        details:
          summary: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
          service: '{{ .GroupLabels.service }}'
          runbook: '{{ range .Alerts }}{{ .Annotations.runbook_url }}{{ end }}'
        severity: 'critical'
        class: 'security'
        component: 'trust-service'
    
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_SECURITY:-}'
        channel: '#security-critical'
        title: 'ðŸš¨ CRITICAL SECURITY ALERT'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}
          
          ðŸ“Š *Details:*
          â€¢ Service: {{ .Labels.service }}
          â€¢ Source IP: {{ .Labels.source_ip }}
          â€¢ Event Type: {{ .Labels.event_type }}
          
          ðŸ“š [Runbook]({{ .Annotations.runbook_url }})
          ðŸ“ˆ [Dashboard]({{ .Annotations.dashboard_url }})
          {{ end }}
        color: 'danger'
    
    email_configs:
      - to: '${SECURITY_EMAIL:-security@marty.com}'
        subject: 'ðŸš¨ CRITICAL SECURITY ALERT: {{ .GroupLabels.alertname }}'
        body: |
          CRITICAL SECURITY ALERT
          
          {{ range .Alerts }}
          Summary: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          
          Details:
          - Service: {{ .Labels.service }}
          - Severity: {{ .Labels.severity }}
          - Source IP: {{ .Labels.source_ip }}
          - Event Type: {{ .Labels.event_type }}
          - User Agent: {{ .Labels.user_agent }}
          
          Actions Required:
          1. Review the security dashboard immediately
          2. Follow the runbook procedures
          3. Escalate to security team lead if needed
          
          Runbook: {{ .Annotations.runbook_url }}
          Dashboard: {{ .Annotations.dashboard_url }}
          {{ end }}
        headers:
          X-Alert-Priority: 'critical'
          X-Alert-Type: 'security'

  # Critical platform alerts
  - name: 'platform-critical'
    pagerduty_configs:
      - routing_key: '${PAGERDUTY_PLATFORM_KEY:-}'
        description: 'CRITICAL: {{ .GroupLabels.alertname }} - {{ .GroupLabels.service }}'
        details:
          summary: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
          service: '{{ .GroupLabels.service }}'
          severity: '{{ .GroupLabels.severity }}'
          runbook: '{{ range .Alerts }}{{ .Annotations.runbook_url }}{{ end }}'
        severity: 'critical'
        class: 'platform'
        component: 'trust-service'
    
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_PLATFORM:-}'
        channel: '#platform-critical'
        title: 'ðŸ”¥ CRITICAL SYSTEM ALERT'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}
          
          ðŸ“Š *Metrics:*
          â€¢ Service: {{ .Labels.service }}
          â€¢ Instance: {{ .Labels.instance }}
          â€¢ Team: {{ .Labels.team }}
          
          ðŸ› ï¸ [Runbook]({{ .Annotations.runbook_url }})
          ðŸ“ˆ [Dashboard]({{ .Annotations.dashboard_url }})
          {{ end }}
        color: 'danger'
    
    webhook_configs:
      - url: '${WEBHOOK_INCIDENT_MANAGEMENT:-}'
        http_config:
          basic_auth:
            username: '${WEBHOOK_USERNAME:-}'
            password: '${WEBHOOK_PASSWORD:-}'
        send_resolved: true

  # Security warnings
  - name: 'security-warnings'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_SECURITY:-}'
        channel: '#security-alerts'
        title: 'âš ï¸ Security Warning'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}
          
          Service: {{ .Labels.service }} | Severity: {{ .Labels.severity }}
          {{ if .Annotations.runbook_url }}[Runbook]({{ .Annotations.runbook_url }}){{ end }}
          {{ end }}
        color: 'warning'
    
    email_configs:
      - to: '${SECURITY_EMAIL:-security@marty.com}'
        subject: '[SECURITY WARNING] {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Security Warning: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          
          {{ if .Annotations.runbook_url }}Runbook: {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}

  # Platform warnings
  - name: 'platform-warnings'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_PLATFORM:-}'
        channel: '#platform-alerts'
        title: 'âš ï¸ Platform Warning'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Labels.service }} - {{ .Annotations.description }}
          {{ end }}
        color: 'warning'

  # Business team notifications
  - name: 'business-team'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_BUSINESS:-}'
        channel: '#business-metrics'
        title: 'ðŸ“Š Business Metric Alert'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}
          
          ðŸ“ˆ *Business Impact:*
          â€¢ Service: {{ .Labels.service }}
          â€¢ Alert Type: {{ .Labels.alert_type }}
          
          {{ if .Annotations.dashboard_url }}[Business Dashboard]({{ .Annotations.dashboard_url }}){{ end }}
          {{ end }}
        color: '{{ if eq .Status "firing" }}warning{{ else }}good{{ end }}'
    
    email_configs:
      - to: '${BUSINESS_EMAIL:-business@marty.com}'
        subject: '[BUSINESS ALERT] {{ .GroupLabels.alertname }}'
        body: |
          Business Alert
          
          {{ range .Alerts }}
          Summary: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          
          Business Impact:
          - Alert Type: {{ .Labels.alert_type }}
          - Severity: {{ .Labels.severity }}
          
          {{ if .Annotations.dashboard_url }}Dashboard: {{ .Annotations.dashboard_url }}{{ end }}
          {{ if .Annotations.runbook_url }}Runbook: {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}

  # Compliance team notifications
  - name: 'compliance-team'
    email_configs:
      - to: '${COMPLIANCE_EMAIL:-compliance@marty.com}'
        subject: '[COMPLIANCE ALERT] {{ .GroupLabels.alertname }}'
        body: |
          Compliance Alert
          
          {{ range .Alerts }}
          Summary: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          
          Compliance Details:
          - Service: {{ .Labels.service }}
          - Regulation: {{ .Labels.regulation }}
          - Check Type: {{ .Labels.check_type }}
          - Result: {{ .Labels.result }}
          
          Action Required: Review compliance status and take corrective action
          
          {{ if .Annotations.runbook_url }}Runbook: {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        headers:
          X-Alert-Type: 'compliance'
    
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_COMPLIANCE:-}'
        channel: '#compliance-alerts'
        title: 'âš–ï¸ Compliance Alert'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}
          
          Regulation: {{ .Labels.regulation }}
          {{ end }}
        color: 'danger'

  # Escalation team - for prolonged critical issues
  - name: 'escalation-team'
    pagerduty_configs:
      - routing_key: '${PAGERDUTY_ESCALATION_KEY:-}'
        description: 'ESCALATION: {{ .GroupLabels.alertname }} - prolonged critical issue'
        details:
          summary: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
          escalation_reason: 'Critical alert firing for extended period'
          service: '{{ .GroupLabels.service }}'
        severity: 'critical'
        class: 'escalation'
    
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_ESCALATION:-}'
        channel: '#escalation'
        title: 'ðŸš¨ ESCALATION REQUIRED'
        text: |
          {{ range .Alerts }}
          *ESCALATION: {{ .Annotations.summary }}*
          
          ðŸ”¥ This critical alert has been firing for an extended period
          
          Original Alert: {{ .Labels.alertname }}
          Service: {{ .Labels.service }}
          Duration: Extended (>15 minutes)
          
          **IMMEDIATE ACTION REQUIRED**
          
          {{ if .Annotations.runbook_url }}[Runbook]({{ .Annotations.runbook_url }}){{ end }}
          {{ end }}
        color: 'danger'
    
    email_configs:
      - to: '${ESCALATION_EMAIL:-escalation@marty.com}'
        subject: 'ðŸš¨ ESCALATION: {{ .GroupLabels.alertname }} - IMMEDIATE ACTION REQUIRED'
        body: |
          ESCALATION ALERT - IMMEDIATE ACTION REQUIRED
          
          {{ range .Alerts }}
          A critical alert has been firing for an extended period and requires immediate escalation.
          
          Original Alert: {{ .Labels.alertname }}
          Summary: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          Severity: {{ .Labels.severity }}
          
          Escalation Reason: Critical alert firing for more than 15 minutes
          
          REQUIRED ACTIONS:
          1. Acknowledge this escalation immediately
          2. Assemble incident response team
          3. Follow escalation procedures in runbook
          4. Provide status updates every 15 minutes
          
          {{ if .Annotations.runbook_url }}Runbook: {{ .Annotations.runbook_url }}{{ end }}
          {{ if .Annotations.dashboard_url }}Dashboard: {{ .Annotations.dashboard_url }}{{ end }}
          {{ end }}
        headers:
          X-Priority: 'urgent'
          X-Alert-Type: 'escalation'

# Time-based routing for different notification schedules
time_intervals:
  # Business hours (9 AM to 6 PM, Monday to Friday, UTC)
  - name: business_hours
    time_intervals:
      - times:
          - start_time: '09:00'
            end_time: '18:00'
        weekdays: ['monday:friday']
  
  # Off hours
  - name: off_hours
    time_intervals:
      - times:
          - start_time: '18:00'
            end_time: '09:00'
        weekdays: ['monday:friday']
      - times:
          - start_time: '00:00'
            end_time: '23:59'
        weekdays: ['saturday', 'sunday']

# Mute rules for maintenance windows
mute_time_intervals:
  # Scheduled maintenance window
  - name: maintenance_window
    time_intervals:
      - times:
          - start_time: '02:00'
            end_time: '04:00'
        weekdays: ['sunday']